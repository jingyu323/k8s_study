# 存储相关

## 存储方案

DAS（直连存储）
　　是一种存储设备与服务器直接相连的架构。DAS为服务器提供块级的存储服务（不是文件系统级）。
DAS分为内部DAS和外部DAS两类：
内部DAS：
　　在内部DAS架构中，存储设备通过服务器机箱内部的并行或串行总线连接到服务器上。但是，物理的总线有距离限制，只能支持短距离的高速数据传输。此外，很多内部总线能连接的设备数目也有限，并且将存储设备放在服务器机箱内部，也会占用大量的空间 ，对服务器其它部件的维护造成困难。
外部DAS：
　　在外部DAS结构中，服务器与外部的存储设备直接相连。在大多数情况下，他们之间通过FC协议或者SCSI协议进行通信。与内部DAS相比，外部DAS克服了内部DAS对连接设备的距离和数量的限制。另外，外部DAS还可以提供存储设备集中化管理，更加方便。
NAS（网络附加存储）
　　是连接到一个局域网的基于IP的文件共享设备。NAS通过文件级的数据访问和共享提供存储资源，使客户能够以最小的存储管理开销快速直接共享文件；采用NAS可以不用建立多个文件服务器，是首选的文件共享存储解决方案； NAS还有助于消除用户访问通用服务器时的瓶颈；NAS使用网络和文件共享协议进行归档和存储，这些协议包括进行数据传输的TCP/IP和提供远程文件服务的CIFS（通用网络文件系统）、NFS（网络文件系统）。注意：采用NAS共享的时候，UNIX通常使用用NFS，Windows使用CIFS。
拓展：
　　随着网络技术的发展，NAS扩展到用于满足企业访问数据高性能和高可靠性的需求。 NAS设备是专用的、高性能的、高速的、单一用途的文件服务和存储系统。
SAN（存储区域网络）
　　是一个用在服务器和存储资源之间的、专用的、高性能的网络体系。它为了实现大量原始数据的传输而进行了专门的优化。因此，可以把FC SAN看成是对SCSI协议在长距离应用上的扩展（原先的SCSI协议最大的传输距离是6米）。FC SAN使用的典型协议组是SCSI和Fiber Channel 。 Fiber Channel特别适合这项应用，原因在于一方面它可以传输大块数据，另一方面它能够实现远距离传输。
实现IP SAN的典型协议是iSCSI，它定义了SCSI指令集在IP网络中传输的封装方式。
拓展：
　　SAN和NAS最大的区别就是NAS可以给计算节点提供文件系统 对于结算节点来说，拿到的直接就是可以共享的文件夹（共享目录）一样的感觉，但是SAN方案给计算节点提供的是一个裸盘，是无法直接进行使用的，需要对其进行格式化分区，部署文件系统等等操作以后才可以使用。 

## 数据与信息

​        数据和信息是相互联系的，数据是反映客观事务属性的记录，是信息的具体表现形式。而数据经过处理和加工以后就变成信息，而信息是需要经过数字化处理转变成数据记才能进行存储和传输。
信息论观点：
​        数据=信息+数据冗余
简而言之：
​        信息就是数据中包含的有用的东西。
​        从数据中经过用户指定的规则或者特定需求场景下提炼出来的信息能够为企业带来以下好处：

市场以及客户行为的信息
更高效的运营业务
帮助确定风险因素 

## RAID 

### 基本原理

RAID （ Redundant Array of Independent Disks ）即独立磁盘冗余阵列，通常简称为磁盘阵列。简单地说， RAID 是由多个独立的高性能磁盘驱动器组成的磁盘子系统，从而提供比单个磁盘更高的存储性能和数据冗余的技术。 RAID 是一类多磁盘管理技术，其向主机环境提供了成本适中、数据可靠性高的高性能存储。 SNIA 对 RAID 的定义是 [2] ：一种磁盘阵列，部分物理存储空间用来记录保存在剩余空间上的用户数据的冗余信息。当其中某一个磁盘或访问路径发生故障时，冗余信息可用来重建用户数据。磁盘条带化虽然与 RAID 定义不符，通常还是称为 RAID （即 RAID0 ）。

RAID 的初衷是为大型服务器提供高端的存储功能和冗余的数据安全。在整个系统中， RAID 被看作是由两个或更多磁盘组成的存储空间，通过并发地在多个磁盘上读写数据来提高存储系统的 I/O 性能。大多数 RAID 等级具有完备的数据校验、纠正措施，从而提高系统的容错性，甚至镜像方式，大大增强系统的可靠性， Redundant 也由此而来



RAID

https://cloud.tencent.com/developer/article/2046751



RDMA

https://zhuanlan.zhihu.com/p/506835089





# CIFS和NFS的区别

（1）CIFS面向网络连接的共享协议，对网络传输的可靠性要求高，常使用TCP/IP；NFS是独立于传输的，可使用TCP或UDP；

（2）NFS缺点之一，是要求client必须安装专用软件；而CIFS集成在OS 内部，无需额外添加软件；

（3）NFS属无状态协议，而CIFS属有状态协议；NFS受故障影响小，可以自恢复交互过程，CIFS不行；从传输效率上看，CIFS优于NFS，没用太多冗余信息传送；

（4）两协议都需要文件格式转换，NFS保留了unix的文件格式特性，如所有人、组等等；CIFS则完全按照win的风格来作。





# 存储系统架构演变

https://sunjian.blog.csdn.net/article/details/125111808



# SmartThin

https://blog.csdn.net/sj349781478/article/details/125116173



## RTO和RPO



# 完全备份、增量备份和差异备份的区别在哪里？

![](images\backup.png)\



# 热备、冷备、双活

**两地 = 本地 + 异地**

**三中心 = 本地中心 + 本地容灾中心 +异地备份中心**

主备数据中心之间一般有热备、冷备、双活三种备份方式。

**热备**的情况下，只有主数据中心承担用户的业务，在**不停机情况下**对主数据中心进行备份。

**冷备**的情况下，也是只有主数据中心承担业务，在**停机情况下**对主数据中心进行备份。

**双活**是觉得备用数据中心只做备份太浪费了，所以让主备两个数据中心都同时承担用户的业务，此时，主备两个数据中心互为备份，并且进行实时备份。一般来说，主数据中心的负载可能会多一些，比如分担60~70%的业务，备数据中心只分担40%~30%的业务 。



# [共享存储、C/S和B/S架构、存储的分类和区别（SAN、NAS、DAS）、存储共享的过程](https://www.cnblogs.com/yunjisuanchengzhanglu/p/16040054.html)



DAS（Direct Attached Storage—直接连接存储），是指将存储设备通过SCSI接口或[光纤通道](http://baike.baidu.com/view/15247.htm)直接连接到服务器上

https://www.cnblogs.com/yunjisuanchengzhanglu/p/16040054.html
=======
## 容灾和备份的区别
  - 容灾的对象一般是大批量的数据，例如主用数据中心中的所有的生产数据，核心业务数据等，需要在主用数据中心或者主用业务链路出现故障时进行大范围大批量的数据迁移，以保证业务数据的不丢失和整体业务的连续性
  - 备份相对于容灾来说需要备份的数据是比较小规模的，具有明确的针对性的数据，比如针对某一个可靠性要求较高的业务数据或者某一个租户的数据等。
## 存储方案


## 磁盘数据写入方式：

-  buffer io
   -  使用Buffer I/O的时候才在内存与磁盘中间加了一层page cache。
   数据在写入的时候，数据会被先写入page cache。如果用户采用的时同步写(synchronous write)，则数据会立即从page cache写回到磁盘中；如果使用的时延迟写(deferred writes)，那么应用程序就完全不需要等到数据全部被写回到磁盘，数据只要被写到页缓存中就可以了，操作系统会定期将页缓存中的数据刷回到磁盘。而标准IO库中的一组带缓存的io函数（fopen，fread，fwrite等函数），每次调用则不直接调用内核函数，而是在用户态中创建缓存，等到一定量时才和内核交互，其中调用fflush则可以将用户态的数据刷到内核态的内存页中。
   - 优缺点
     - 优点：减少了磁盘的交互次数，由内核控制读取写入时机。
     缺点：数据需要在用户态和内核态进行多次交互，增加了内核开销；其次若机器突然宕机，则数据可能会丢失
-  mmap
   -  MMap(Memort-map) IO 能将一个磁盘文件映射到存储空间中（用户态）的一个缓存区上，于是，当从缓存区中读取数据时，就相当于读文件中的相应字节。于此类似，将数据存入缓存区时，相应字节就自动写入文件。这样就可以不使用read和write的情况下执行I/O，因此减少了内核态到用户态，用户态到内核态的多次转换。可以调用msync将mmap的page cache刷入磁盘中
   -  优缺点
   优点： 减少了内核态到用户态交互的开销，减少了磁盘的交互次数。
   缺点：机器宕机，还没写写入磁盘的数据会丢失。
-  direct io
   -  Linux允许应用程序在执行磁盘IO时绕过缓冲区高速缓存，从用户空间直接将数据传递到文件或磁盘设备，称为直接IO（direct IO）或者裸IO（raw IO）
   -  优点：如果要传输的数据量很大，降低数据在page cache中的拷贝带来的开销，提高性能。
   缺点：Direct I/O的开销大，因为没有page cache的使用，因此内核中很多对page cache的优化也无法使用（例如：按顺序预读取，在成簇磁盘块上执行IO，允许访问同一文件的多个进程共享高速缓存的缓冲区等）

## RAID


## 硬盘类型：
### SSD
### SAS
### NL-SAS

## RAID2.0+





**TOE网卡和iSCSI HBA卡有什么区别**

TOE网卡是指带有TOE功能的网卡。TOE是TCP/IP Offload Engine的缩写，它是网卡采用的一种新技术，采用TOE技术的网卡自身支持TCP/IP协议栈的处理，这样能够减轻应用服务器的处理负担。TOE网卡通常用于高速网络接口，如千兆和万兆网络。

iSCSI HBA（Host Bus Adapter）卡是专用的连接iSCSI设备的主机适配卡，它支持TOE的同时还支持对iSCSI协议的处理，能够更进一步的减轻应用服务器的处理负担



# 存储基础：LUN、ThickLUN与Thin LUN的联系和区别

原文链接：https://blog.csdn.net/M_joy666/article/details/80566705

一、基本概念

       LUN：全称是Logical Unit Number，中文名是逻辑单元号。LUN是在存储设备上可以被应用服务器识别的独立存储单元。一个LUN的空间来源于存储池Pool，Pool的空间来源于组成磁盘阵列的若干块硬盘。从应用服务器的角度来看，一个LUN可以被视为一块可以使用的硬盘。例如，在Linux系统中，它在/dev/rdsk、/dev/dsk目录下有相应的设备名称；在Windows系统中，格式化后的新LUN会对应一个类似于D E F的盘符。
    
      Thick LUN：中文名是传统非精简LUN，是LUN类型的一种，支持虚拟资源分配，能以较为简便的方式进行创建、扩容和压缩操作。Thick LUN在创建完成后就会从存储池Pool中分配满额的存储空间，即LUN的大小完全等于分配的空间。因此，它拥有较高的可预测性。
    
      Thin LUN：中文名是精简LUN，也是LUN类型的一种，支持虚拟资源分配，能够以较简便的方式进行创建、扩容和压缩操作。Thin LUN在创建的时候，可以设置一个初始分配容量。创建完成后，存储池Pool只会分配这个初始容量大小的空间剩余的空间仍然放在存储池中。当Thin LUN已分配的存储空间的使用率达到阈值时，存储系统才会再从Pool中划分一定的配额给Thin LUN。如此反复，直到达到Thin LUN最初设定的全部容量。因此，它拥有较高的存储空间利用率。

二、Thick LUN与Thin LUN的区别

 1、空间分配上的区别

Thick LUN在创建时会分配所有需要的空间
Thin LUN是一种按需分配的空间组织方法，它在创建时存储池不会分配所有需要的空间，而是根据使用情况动态分配。
    二者的空间分配区别如下图所示：



 2、空间回收的区别

  注：这里的空间回收指的是释放存储池Pool中的资源，并且这些资源可以被其他LUN使用。

Thick LUN没有空间回收的概念，因为它在创建时就占用存储池中所有分配给它的空间，即使Thick LUN中的数据被删除，存储池中分配给它的空间还是被占用，不能被其他的LUN使用。但是如果手动删除不再使用的Thick LUN，则对应的空间会被回收。
Thin LUN不仅能够做到空间占用率增大时自动分配新的存储空间，而且当Thin LUN中的文件删除时也可以实现空间的释放，从而实现存储空间的反复利用，大大提高存储空间的利用率。Thin LUN的空间回收如下图所示：

 3、性能的区别

Thick LUN由于在一开始就会拥有所分配的空间，所以Thick LUN在顺序读写的时候拥有较高的性能，但是会造成空间资源的浪费。
Thin LUN由于是实时分配空间，每次扩容时，需要重新增加容量，后台重新格式化，这个时候性能会受到一定影响，而且每次分配空间可能会导致硬盘中存储空间不连续，这样硬盘读写数据时在寻找存放位置上花费的时间会较多，会在顺序读写时对性能有一定影响。
 4、使用场景的区别

Thick LUN：①对性能要求较高的场景；②对存储空间利用率不太敏感的场景；③对成本要求不太高的场景。
Thin LUN：①对性能要求一般的场景；②对存储空间利用率比较敏感的场景；③对成本比较敏感的场景；④应用环境很难预 估存储空间的场景
三、总结

      总而言之，Thick LUN和Thin LUN各有特点。Thick LUN的性能较高，但是会造成空间资源的浪费；Thin LUN可以灵活配置使用存储池中的空间，但是会导致分配的存储空间不连续，所以性能不高。具体使用哪一种还需视情况而定。




| HyperSnap        | 就是快照，有COW和ROW；                                       |
| ---------------- | ------------------------------------------------------------ |
| HyperClone       | 分主LUN，从LUN；从生产数据中快速复制出副本，并独立共享给应用服务器读写，用于测试、分析或者容灾演练等应用，同时不影响生产数据。 主要的点，在于 目标LUN是立刻可读写的，不需要等待后台拷贝完成； 当源LUN损坏之后，目标LUN可以反向同步数据到源LUN完成数据恢复； |
| HyperCopy        | LUN拷贝会将所有数据进行完整地复制，需要暂停该LUN的业务。     |
| HyperMirror      | ● 对一个LUN提供两个镜像物理副本，这两个副本中的数据是完全一样的。当其中的一个镜像副本出现故障时，LUN上的业务不受任何影响，主机侧仍然可以毫无感知的正常工作。● 这个被持续保护的LUN可以是OceanStor系列存储系统（以下简称为本端存储系统）的LUN，也可以是第三方存储系统（以下简称异构存储系统）的LUN。 |
| HyperReplication | 指的是远程复制，主要是为了异地冗余；远程复制支持以下两种复制模式：● 同步远程复制实时地同步数据，最大限度保证数据的一致性，以减少灾难发生时的数据丢失量。● 异步远程复制周期性地同步数据，最大限度减少由于数据远程传输的时延而造成的业务性能下降。 是用于主备容灾，通过将源LUN与目标LUN建立pair关系，来进行数据同步； |
