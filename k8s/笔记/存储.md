# 存储相关

## RAID 

### 基本原理

RAID （ Redundant Array of Independent Disks ）即独立磁盘冗余阵列，通常简称为磁盘阵列。简单地说， RAID 是由多个独立的高性能磁盘驱动器组成的磁盘子系统，从而提供比单个磁盘更高的存储性能和数据冗余的技术。 RAID 是一类多磁盘管理技术，其向主机环境提供了成本适中、数据可靠性高的高性能存储。 SNIA 对 RAID 的定义是 [2] ：一种磁盘阵列，部分物理存储空间用来记录保存在剩余空间上的用户数据的冗余信息。当其中某一个磁盘或访问路径发生故障时，冗余信息可用来重建用户数据。磁盘条带化虽然与 RAID 定义不符，通常还是称为 RAID （即 RAID0 ）。

RAID 的初衷是为大型服务器提供高端的存储功能和冗余的数据安全。在整个系统中， RAID 被看作是由两个或更多磁盘组成的存储空间，通过并发地在多个磁盘上读写数据来提高存储系统的 I/O 性能。大多数 RAID 等级具有完备的数据校验、纠正措施，从而提高系统的容错性，甚至镜像方式，大大增强系统的可靠性， Redundant 也由此而来



RAID

https://cloud.tencent.com/developer/article/2046751



RDMA

https://zhuanlan.zhihu.com/p/506835089





# CIFS和NFS的区别

（1）CIFS面向网络连接的共享协议，对网络传输的可靠性要求高，常使用TCP/IP；NFS是独立于传输的，可使用TCP或UDP；

（2）NFS缺点之一，是要求client必须安装专用软件；而CIFS集成在OS 内部，无需额外添加软件；

（3）NFS属无状态协议，而CIFS属有状态协议；NFS受故障影响小，可以自恢复交互过程，CIFS不行；从传输效率上看，CIFS优于NFS，没用太多冗余信息传送；

（4）两协议都需要文件格式转换，NFS保留了unix的文件格式特性，如所有人、组等等；CIFS则完全按照win的风格来作。





# 存储系统架构演变

https://sunjian.blog.csdn.net/article/details/125111808



# SmartThin

https://blog.csdn.net/sj349781478/article/details/125116173



## RTO和RPO



# 完全备份、增量备份和差异备份的区别在哪里？

![](images\backup.png)\



# 热备、冷备、双活

**两地 = 本地 + 异地**

**三中心 = 本地中心 + 本地容灾中心 +异地备份中心**

主备数据中心之间一般有热备、冷备、双活三种备份方式。

**热备**的情况下，只有主数据中心承担用户的业务，在**不停机情况下**对主数据中心进行备份。

**冷备**的情况下，也是只有主数据中心承担业务，在**停机情况下**对主数据中心进行备份。

**双活**是觉得备用数据中心只做备份太浪费了，所以让主备两个数据中心都同时承担用户的业务，此时，主备两个数据中心互为备份，并且进行实时备份。一般来说，主数据中心的负载可能会多一些，比如分担60~70%的业务，备数据中心只分担40%~30%的业务 。



# [共享存储、C/S和B/S架构、存储的分类和区别（SAN、NAS、DAS）、存储共享的过程](https://www.cnblogs.com/yunjisuanchengzhanglu/p/16040054.html)





https://www.cnblogs.com/yunjisuanchengzhanglu/p/16040054.html
=======
## 容灾和备份的区别
  - 容灾的对象一般是大批量的数据，例如主用数据中心中的所有的生产数据，核心业务数据等，需要在主用数据中心或者主用业务链路出现故障时进行大范围大批量的数据迁移，以保证业务数据的不丢失和整体业务的连续性
  - 备份相对于容灾来说需要备份的数据是比较小规模的，具有明确的针对性的数据，比如针对某一个可靠性要求较高的业务数据或者某一个租户的数据等。
## 存储方案


## 磁盘数据写入方式：

-  buffer io
   -  使用Buffer I/O的时候才在内存与磁盘中间加了一层page cache。
   数据在写入的时候，数据会被先写入page cache。如果用户采用的时同步写(synchronous write)，则数据会立即从page cache写回到磁盘中；如果使用的时延迟写(deferred writes)，那么应用程序就完全不需要等到数据全部被写回到磁盘，数据只要被写到页缓存中就可以了，操作系统会定期将页缓存中的数据刷回到磁盘。而标准IO库中的一组带缓存的io函数（fopen，fread，fwrite等函数），每次调用则不直接调用内核函数，而是在用户态中创建缓存，等到一定量时才和内核交互，其中调用fflush则可以将用户态的数据刷到内核态的内存页中。
   - 优缺点
     - 优点：减少了磁盘的交互次数，由内核控制读取写入时机。
     缺点：数据需要在用户态和内核态进行多次交互，增加了内核开销；其次若机器突然宕机，则数据可能会丢失
-  mmap
   -  MMap(Memort-map) IO 能将一个磁盘文件映射到存储空间中（用户态）的一个缓存区上，于是，当从缓存区中读取数据时，就相当于读文件中的相应字节。于此类似，将数据存入缓存区时，相应字节就自动写入文件。这样就可以不使用read和write的情况下执行I/O，因此减少了内核态到用户态，用户态到内核态的多次转换。可以调用msync将mmap的page cache刷入磁盘中
   -  优缺点
   优点： 减少了内核态到用户态交互的开销，减少了磁盘的交互次数。
   缺点：机器宕机，还没写写入磁盘的数据会丢失。
-  direct io
   -  Linux允许应用程序在执行磁盘IO时绕过缓冲区高速缓存，从用户空间直接将数据传递到文件或磁盘设备，称为直接IO（direct IO）或者裸IO（raw IO）
   -  优点：如果要传输的数据量很大，降低数据在page cache中的拷贝带来的开销，提高性能。
   缺点：Direct I/O的开销大，因为没有page cache的使用，因此内核中很多对page cache的优化也无法使用（例如：按顺序预读取，在成簇磁盘块上执行IO，允许访问同一文件的多个进程共享高速缓存的缓冲区等）

## RAID


## 硬盘类型：
### SSD
### SAS
### NL-SAS

## RAID2.0+





**TOE网卡和iSCSI HBA卡有什么区别**

TOE网卡是指带有TOE功能的网卡。TOE是TCP/IP Offload Engine的缩写，它是网卡采用的一种新技术，采用TOE技术的网卡自身支持TCP/IP协议栈的处理，这样能够减轻应用服务器的处理负担。TOE网卡通常用于高速网络接口，如千兆和万兆网络。

iSCSI HBA（Host Bus Adapter）卡是专用的连接iSCSI设备的主机适配卡，它支持TOE的同时还支持对iSCSI协议的处理，能够更进一步的减轻应用服务器的处理负担



# 存储基础：LUN、ThickLUN与Thin LUN的联系和区别

原文链接：https://blog.csdn.net/M_joy666/article/details/80566705

一、基本概念

       LUN：全称是Logical Unit Number，中文名是逻辑单元号。LUN是在存储设备上可以被应用服务器识别的独立存储单元。一个LUN的空间来源于存储池Pool，Pool的空间来源于组成磁盘阵列的若干块硬盘。从应用服务器的角度来看，一个LUN可以被视为一块可以使用的硬盘。例如，在Linux系统中，它在/dev/rdsk、/dev/dsk目录下有相应的设备名称；在Windows系统中，格式化后的新LUN会对应一个类似于D E F的盘符。
    
      Thick LUN：中文名是传统非精简LUN，是LUN类型的一种，支持虚拟资源分配，能以较为简便的方式进行创建、扩容和压缩操作。Thick LUN在创建完成后就会从存储池Pool中分配满额的存储空间，即LUN的大小完全等于分配的空间。因此，它拥有较高的可预测性。
    
      Thin LUN：中文名是精简LUN，也是LUN类型的一种，支持虚拟资源分配，能够以较简便的方式进行创建、扩容和压缩操作。Thin LUN在创建的时候，可以设置一个初始分配容量。创建完成后，存储池Pool只会分配这个初始容量大小的空间剩余的空间仍然放在存储池中。当Thin LUN已分配的存储空间的使用率达到阈值时，存储系统才会再从Pool中划分一定的配额给Thin LUN。如此反复，直到达到Thin LUN最初设定的全部容量。因此，它拥有较高的存储空间利用率。

二、Thick LUN与Thin LUN的区别

 1、空间分配上的区别

Thick LUN在创建时会分配所有需要的空间
Thin LUN是一种按需分配的空间组织方法，它在创建时存储池不会分配所有需要的空间，而是根据使用情况动态分配。
    二者的空间分配区别如下图所示：



 2、空间回收的区别

  注：这里的空间回收指的是释放存储池Pool中的资源，并且这些资源可以被其他LUN使用。

Thick LUN没有空间回收的概念，因为它在创建时就占用存储池中所有分配给它的空间，即使Thick LUN中的数据被删除，存储池中分配给它的空间还是被占用，不能被其他的LUN使用。但是如果手动删除不再使用的Thick LUN，则对应的空间会被回收。
Thin LUN不仅能够做到空间占用率增大时自动分配新的存储空间，而且当Thin LUN中的文件删除时也可以实现空间的释放，从而实现存储空间的反复利用，大大提高存储空间的利用率。Thin LUN的空间回收如下图所示：

 3、性能的区别

Thick LUN由于在一开始就会拥有所分配的空间，所以Thick LUN在顺序读写的时候拥有较高的性能，但是会造成空间资源的浪费。
Thin LUN由于是实时分配空间，每次扩容时，需要重新增加容量，后台重新格式化，这个时候性能会受到一定影响，而且每次分配空间可能会导致硬盘中存储空间不连续，这样硬盘读写数据时在寻找存放位置上花费的时间会较多，会在顺序读写时对性能有一定影响。
 4、使用场景的区别

Thick LUN：①对性能要求较高的场景；②对存储空间利用率不太敏感的场景；③对成本要求不太高的场景。
Thin LUN：①对性能要求一般的场景；②对存储空间利用率比较敏感的场景；③对成本比较敏感的场景；④应用环境很难预 估存储空间的场景
三、总结

      总而言之，Thick LUN和Thin LUN各有特点。Thick LUN的性能较高，但是会造成空间资源的浪费；Thin LUN可以灵活配置使用存储池中的空间，但是会导致分配的存储空间不连续，所以性能不高。具体使用哪一种还需视情况而定。
